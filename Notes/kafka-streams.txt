Video or a live feed comprises multiple pieces. Streaming allows processing each piece individually.


Kafka Streams Core Concepts
---------------------------

Stream - is a sequence of immutable data records, that are fully ordered, can be replayed,
and is fault-tolerant (think of a Kafka Topic as a parallel).

Stream processor - is a node in the processor topology. It transforms incoming streams, record by record, and may create
a new stream from it.

topology - is a graph of processors chained together by streams

A Source Processor - is a processor that does not have children, it sends the stream data directly to a Kafka topic.

A Sink processor - is a special processor that takes it data directly from a kafka topic. It has no predecessors in a topology,
and doesn't transform the data.

having the 2 logging libraries in build.gradle of kafka-streams module help in getting more logs that help in debugging
    implementation group: 'org.slf4j', name: 'slf4j-api', version: '1.7.36'
    implementation group: 'org.slf4j', name: 'slf4j-log4j12', version: '1.7.36', ext: 'pom'

Kafka Streams Topology
----------------------
to print the streams topology add toString() on the kafkastream object -
 log.info ("streams topology: {}", kafkaStreams.toString());
WordCountApp.java


KStream and Stream
------------------
KStream is an abstraction over Stream.
Unbounded sequence of Structured data. Streams are discreet entries long-running and never ending. Structured data is called -
Events, Messages, facts. These Stream objects are immutable

KTable
------
is a collection of evolving facts


