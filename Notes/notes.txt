brew services start zookeeper

brew services start kafka


To have launchd start zookeeper now and restart at login:
Â  brew services start zookeeper
Or, if you don't want/need a background service you can just run:
Â  zkServer start
==> Summary
ðŸºÂ  /usr/local/Cellar/zookeeper/3.7.0: 1,073 files, 42.4MB
==> Installing kafka
==> Pouring kafka--2.8.0.catalina.bottle.tar.gz
==> Caveats

To have launchd start kafka now and restart at login:
Â  brew services start kafka
Or, if you don't want/need a background service you can just run:
Â  zookeeper-server-start -daemon /usr/local/etc/kafka/zookeeper.properties & kafka-server-start /usr/local/etc/kafka/server.properties
==> Summary
ðŸºÂ  /usr/local/Cellar/kafka/2.8.0: 200 files, 68.2MB
==> Caveats

==> zookeeper
To have launchd start zookeeper now and restart at login:
Â  brew services start zookeeper
Or, if you don't want/need a background service you can just run:
Â  zkServer start
==> kafka
To have launchd start kafka now and restart at login:
Â  brew services start kafka
Or, if you don't want/need a background service you can just run:
Â  zookeeper-server-start -daemon /usr/local/etc/kafka/zookeeper.properties & kafka-server-start /usr/local/etc/kafka/server.properties


ZooKeeper
---------
As daemon process -
	zookeeper-server-start -daemon /usr/local/etc/kafka/zookeeper.properties
Not as daemon process -
	zookeeper-server-start /usr/local/etc/kafka/zookeeper.properties

Kafka Server
------------
Not as daemon process -
	kafka-server-start /usr/local/etc/kafka/server.propertiesÂ 
As daemon process -
	kafka-server-start -daemon /usr/local/etc/kafka/server.properties

Start both zookeeper and kafka together
----------------------------------------
zookeeper-server-start -daemon /usr/local/etc/kafka/zookeeper.properties & kafka-server-start /usr/local/etc/kafka/server.properties

Kafka Topic Commands
-------------------------------
Creating a topic -
	With specific configuration
		kafka-topics --bootstrap-server localhost:9092 --topic first-topic --create --partitions 3 --replication-factor 1
	With all defaults -
		kafka-topics --bootstrap-server localhost:9092 --topic first-topic --create
Listing topics -
	 kafka-topics --bootstrap-server localhost:9092 --list
Description of a topic -
	kafka-topics --bootstrap-server localhost:9092 --topic first-topic --describe
Deleting a topic -
	kafka-topics --bootstrap-server localhost:9092 --topic first-topic --delete

Kafka-Console-Producer Commands
------------------------------------------------
kafka-console-producer --bootstrap-server localhost:9092 --topic first-topic
There will be a little caret , start typing ur messages. If there is no error messages are successfully sent.
Use Ctl+c to exit the console producer

Producing messages to a non-existent topic ::
	kafka-console-producer --bootstrap-server localhost:9092 --topic non-existing-topic
I changed the default # of partitions by editing the server.properties file at /usr/local/etc/kafka and restarted kafka admin client

After that ::
	kafka-console-producer --bootstrap-server localhost:9092 --topic non-existing-topic_2
New non-existing topic non-existing-topic_2 was created with 3 partitions

Teacher's recommendation is to manually create a topic and then produce messages.

Kafka-Console-Consumer Commands
--------------------------------------------------
Basic command for consuming -
	kafka-console-consumer --bootstrap-server localhost:9092 --topic first-topic
But with this command Messages sent prior to starting consumer will not be consumed. Only those Messages sent after the consumer started will be consumed.

To read the messages from the beginning of the topic use the command -
	kafka-console-consumer --bootstrap-server localhost:9092 --topic first-topic --from-beginning


Kafka-Console-Consumers in a Group
--------------------------------------------------
Command to start the consumers in a group -
	kafka-console-consumer --bootstrap-server localhost:9092 --topic first-topic --group second-consumer-group
Command to start the consumers in a new group to read from start of the topic from beginning
	kafka-console-consumer --bootstrap-server localhost:9092 --topic first-topic --group second-consumer-group --from-beginning

Kafka remembers the offset(index) on every topic that consumer(s) of a group consumed. If u start a consumer of an existing group on existing topic with --from-beginning command it only reads those messages that are not already consumed by an active or a non-active consumer of the same group.
If u start new consumer on new group for a topic that has a bunch of messages on each partition (offset of each partition is > zero) then by default LAG for the new consumer group is zero, meaning new group will not read old messages, will read only new messages, if u want this group to read all the messages from the beginning , then use  --from-beginning option

To see how this works please spin up multiple consumers in the same group


Kafka-consumer-Groups
---------------------------------

List all the consumer groups -
	kafka-consumer-groups --bootstrap-server localhost:9092 --list

Describe a consumer group -
	kafka-consumer-groups --bootstrap-server localhost:9092 --group first-consumer-group --describe
	Lag indicates the delta between CURRENT-OFFSET and LOG-END-OFFSET

Start a consumer of group first-consumer-group in a different Terminal and the run this command to see what output we get
	kafka-consumer-groups --bootstrap-server localhost:9092 --group first-consumer-group --describe
That will list the active consumers and which partitions they are listening to , etc

Reset offset
-----------------
Reset offset will only reset the offset of a specific consumer group
	kafka-consumer-groups --bootstrap-server localhost:9092 --topic first-topic --group first-consumer-group --reset-offsets --to-earliest --executea
Above command resets the offset of first-consumer-group to earliest (0 in this case) , this option is very different from --from-beginning.

	kafka-consumer-groups --bootstrap-server localhost:9092 --group second-consumer-group --topic first-topic --reset-offsetsÂ  --shift-by -2Â  --execute
Above command will reset the offset only by few indexes so the consumer group can read only those and not all from beginning


Kafka Producer with Callback
----------------------------
public void onCompletion(RecordMetadata metadata, Exception exception) {
// this executes every time a message is successfully sent or an exception is thrown

Kafka Producer with Key
-----------------------
Messages with same key goes the same partition
by default producer.send is asynchronous, it can be synchronous by adding get() method. Look at the BasicProducerWithKey.
Run this sample multiple time to see that same key goes to same partition.

Message Key : id_0
Partition : 1

Message Key : id_1
Partition : 0

Message Key : id_2
Partition : 2

Message Key : id_3
Partition : 0

Message Key : id_4
Partition : 2

Message Key : id_5
Partition : 2

Message Key : id_6
Partition : 0

Message Key : id_7
Partition : 2

Message Key : id_8
Partition : 1

Message Key : id_9
Partition : 2

Kafka Consumer
---------------
For AUTO_OFFSET_RESET_CONFIG , there are 3 values available
    earliest - from the beginning of the topic
    latest - from the point consumer is added to topic onwards
    none - will throw error

One consumer can consume from more than one topic

Java Consumer inside a consumer group
-------------------------------------
you can run the Consumer Java application more than once to create multiple consumers in a group.
When u spin and stop consumers look for messages in the console to check for how many stopped and how re-assignment happens.

Ex - message from BasicConsumer1 after 2 and 3 were started
09:19:30.513 [main] INFO  o.a.k.c.c.i.AbstractCoordinator [Consumer clientId=consumer-first-java-consumer-group-1, groupId=first-java-consumer-group] Attempt to heartbeat failed since group is rebalancing
09:19:30.515 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator [Consumer clientId=consumer-first-java-consumer-group-1, groupId=first-java-consumer-group] Revoke previously assigned partitions first-topic-1, first-topic-0
09:19:30.515 [main] INFO  o.a.k.c.c.i.AbstractCoordinator [Consumer clientId=consumer-first-java-consumer-group-1, groupId=first-java-consumer-group] (Re-)joining group
09:19:30.516 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator [Consumer clientId=consumer-first-java-consumer-group-1, groupId=first-java-consumer-group] Finished assignment for group at generation 22: {consumer-first-java-consumer-group-1-6cfecd2a-68ce-47e5-b990-9040dac7edf4=Assignment(partitions=[first-topic-0]), consumer-first-java-consumer-group-1-ffcf31b6-ee27-4e13-96aa-3398669698a0=Assignment(partitions=[first-topic-2]), consumer-first-java-consumer-group-1-948df6b3-b41b-4ede-b7f0-191f95971117=Assignment(partitions=[first-topic-1])}
09:19:30.518 [main] INFO  o.a.k.c.c.i.AbstractCoordinator [Consumer clientId=consumer-first-java-consumer-group-1, groupId=first-java-consumer-group] Successfully joined group with generation 22
09:19:30.518 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator [Consumer clientId=consumer-first-java-consumer-group-1, groupId=first-java-consumer-group] Notifying assignor about the new Assignment(partitions=[first-topic-0])
09:19:30.518 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator [Consumer clientId=consumer-first-java-consumer-group-1, groupId=first-java-consumer-group] Adding newly assigned partitions: first-topic-0
09:19:30.519 [main] INFO  o.a.k.c.c.i.ConsumerCoordinator [Consumer clientId=consumer-first-java-consumer-group-1, groupId=first-java-consumer-group] Setting offset for partition first-topic-0 to the committed offset FetchPosition{offset=57, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[192.168.1.16:9092 (id: 0 rack: null)], epoch=0}}


Java Consumer with Threads
--------------------------
Refer to ConsumerAsThread.java for example, Its slightly complicated.

Java Consumer Assign and Seek
------------------------------
Assign and Seek are mostly used to replay data and fetch a specific message

